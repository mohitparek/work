{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN4g-crwHa-1"
      },
      "outputs": [],
      "source": [
        "# Q1\n",
        "# a.Overfitting :\n",
        "# occurs when a machine learning model learns the training data too well, capturing noise and irrelevant details in addition\n",
        "# to the underlying patterns. As a result,the model performs exceptionally well on the training data but poorly on new, unseen data.\n",
        "# Mitigation:\n",
        "# Use a simpler model with fewer parameters or features.\n",
        "# Collect more training data to reduce the impact of noise.\n",
        "\n",
        "# b.Underfitting occurs when a machine learning model is too simple to capture the underlying patterns in the data. It fails to perform\n",
        "# well both on the training data and on new data because it doesn't learn enough from the training set.\n",
        "# Mitigation:\n",
        "# Use a more complex model with more features or parameters.\n",
        "# Ensure the data is preprocessed correctly, and important features are included."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.\n",
        "# A.Choose a simpler model architecture with fewer parameters or features. For example, use a linear model\n",
        "# instead of a complex deep neural network if the data can be adequately represented with simpler functions.\n",
        "\n",
        "# B.Feature Selection:\n",
        "# Carefully select relevant features and eliminate irrelevant or redundant ones. Feature engineering can play a crucial role in improving model generalization.\n",
        "\n",
        "# C.More Training Data:\n",
        "# Increase the size of the training dataset if possible. More data can help the model capture underlying patterns and reduce the impact of noise."
      ],
      "metadata": {
        "id": "7aDkN8qzHdjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.\n",
        "# Underfitting occurs when a machine learning model is too simple to capture the underlying patterns in the data. It fails to perform\n",
        "# well both on the training data and on new data because it doesn't learn enough from the training set."
      ],
      "metadata": {
        "id": "EqemDU72Hdn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4\n",
        "# Bias refers to the error introduced by approximating a real-world problem, which may be complex, by a simplified model. A high bias model makes\n",
        "# strong assumptions about the data and may underfit, meaning it cannot capture the underlying patterns, resulting in poor performance on both\n",
        "# the training and test data.\n",
        "\n",
        "# Variance is the error introduced by the model's sensitivity to small fluctuations or noise in the training data. A high variance model is too\n",
        "# flexible, capturing noise as well as genuine patterns, and is prone to overfitting. It performs very well on the training data but poorly on new,\n",
        "# unseen data.\n",
        "\n",
        "# note:The goal is to find a model that achieves a balance between bias and variance, where it captures the essential underlying patterns in the data\n",
        "#  without being overly sensitive to noise. This leads to the best generalization to new data."
      ],
      "metadata": {
        "id": "3Zuee9wYHdr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5\n",
        "# 1. Visual Inspection of Learning Curves:\n",
        "\n",
        "#     Plot the training and validation (or test) error (e.g., loss or accuracy) as a function of the number of training iterations or epochs.\n",
        "#     Overfitting: If the training error continues to decrease, but the validation error starts increasing or plateaus, it's a sign of overfitting.\n",
        "#     Underfitting: Both training and validation errors remain high and do not converge.\n",
        "\n",
        "# 2. Cross-Validation:\n",
        "\n",
        "#     Use k-fold cross-validation to assess how well the model generalizes to different data splits.\n",
        "#     Overfitting: If the model performs significantly better on the training folds than on the validation folds, it may be overfitting.\n",
        "#     Underfitting: Poor performance on both training and validation folds indicates underfitting.\n",
        "\n",
        "# 3. Validation Set Performance:\n",
        "\n",
        "#     Monitor the model's performance on a separate validation set during training.\n",
        "#     Overfitting: If the validation performance starts deteriorating after an initial improvement, it suggests overfitting.\n",
        "#     Underfitting: Consistently poor validation performance is a sign of underfitting.\n",
        "\n",
        "# 4. Model Complexity vs. Data Size:\n",
        "\n",
        "#     Observe how the model's performance changes with variations in model complexity and data size.\n",
        "#     Overfitting: A complex model performs better on a smaller dataset but worse on a larger dataset.\n",
        "#     Underfitting: A simple model performs poorly on both small and large datasets."
      ],
      "metadata": {
        "id": "UgXsat04Hduy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6\n",
        "# Bias and variance are two key aspects of a model's performance:\n",
        "\n",
        "# Bias refers to the error introduced by approximating a real-world problem, which may be complex, with a simplified model. High bias models,\n",
        "# like linear regression for complex data, oversimplify and often underfit the data, resulting in poor performance.\n",
        "\n",
        "# Variance is the error introduced by a model's sensitivity to fluctuations or noise in the training data. High variance models, such as deep neural\n",
        "# networks with insufficient training data, overfit the data by capturing noise and perform well on training but poorly on new data.\n",
        "\n",
        "# High bias models generalize too much, while high variance models generalize too little, leading to a trade-off in machine learning for optimal model\n",
        "# performance."
      ],
      "metadata": {
        "id": "4WpPysMSHdx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7\n",
        "# Regularization in machine learning is a technique used to prevent overfitting by adding a penalty term to the model's loss function. It discourages\n",
        "# overly complex models by constraining the values of model parameters. Common regularization techniques include:\n",
        "\n",
        "# 1.L1 Regularization (Lasso):It adds the absolute values of parameter coefficients to the loss, encouraging sparse models with some coefficients\n",
        "# effectively set to zero.\n",
        "\n",
        "# 2.L2 Regularization (Ridge): This technique adds the squared values of parameter coefficients to the loss, encouraging smaller parameter values and\n",
        "# preventing extreme weights.\n",
        "\n",
        "# 3.Elastic Net Regularization: A combination of L1 and L2 regularization, providing a balance between feature selection (L1) and parameter shrinkage (L2).\n",
        "\n",
        "# Regularization techniques reduce model complexity, making it less prone to overfitting while preserving essential features. The strength of\n",
        "# regularization is controlled by a hyperparameter, allowing fine-tuning to find the right balance."
      ],
      "metadata": {
        "id": "IXPmDs2AHd1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kEhiz7JHd4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vd0XdcCRHd7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4DthM94HfN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDDFUVtlHfcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "986q4YfeHfft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-enuTbc5Hfi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grEOROETHfmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1fufGsSIHfpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6MpNqZctHfsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RAyibDQwHfvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "edR2pv6nHfyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQgT3h2OHf15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}